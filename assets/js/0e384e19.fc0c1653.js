(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[671],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return u},kt:function(){return h}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(n),h=a,m=p["".concat(l,".").concat(h)]||p[h]||d[h]||o;return n?r.createElement(m,i(i({ref:t},u),{},{components:n})):r.createElement(m,i({ref:t},u))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,i[1]=s;for(var c=2;c<o;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},426:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return i},metadata:function(){return s},toc:function(){return l},default:function(){return u}});var r=n(2122),a=n(9756),o=(n(7294),n(3905)),i={id:"intro",title:"What is PyTouch?",sidebar_label:"About",slug:"/"},s={unversionedId:"intro",id:"intro",isDocsHomePage:!1,title:"What is PyTouch?",description:"Introduction",source:"@site/docs/intro.md",sourceDirName:".",slug:"/",permalink:"/PyTouch/docs/",editUrl:"https://github.com/facebookresearch/pytouch/edit/master/website/docs/intro.md",version:"current",sidebar_label:"About",frontMatter:{id:"intro",title:"What is PyTouch?",sidebar_label:"About",slug:"/"},sidebar:"docs",next:{title:"Installing PyTouch",permalink:"/PyTouch/docs/install"}},l=[{value:"Introduction",id:"introduction",children:[]},{value:"Key Features",id:"key-features",children:[]},{value:"In Beta",id:"in-beta",children:[]},{value:"Versions",id:"versions",children:[]}],c={toc:l};function u(e){var t=e.components,n=(0,a.Z)(e,["components"]);return(0,o.kt)("wrapper",(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"With the increased availability of rich tactile sensors, the sense of touch is becoming a new and important sensor modality in robotics and machine learning. Sensing the world through touch open exciting new challenges and opportunities to measure, understand and interact with the world around us. However, the availability of ready-to-use touch processing software is extremely limited whichs results in a high entry bar for new practitioners that want to make use of tactile sensors, which are forced to implement their own touch processing routines."),(0,o.kt)("p",null,"PyTouch is an open-source library for touch processing that enables the machine learning and the robotics community to process raw touch data from tactile sensors through abstractions which focus on the experiment instead of the low level details of elementary concepts."),(0,o.kt)("p",null,"The software library modularizes a set of commonly used tactile-processing functions valuable for various down-stream tasks, such as tactile manipulation, slip detection, object recognition based on touch and other touch based tasks."),(0,o.kt)("p",null,"PyTouch aims to standardize the way touch based experiments are designed in reducing the amount of individual software developed for one off experiments by using the PyTouch library as a foundation which can be expanded upon for future experimental and research applications."),(0,o.kt)("h2",{id:"key-features"},"Key Features"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Built with PyTorch"),(0,o.kt)("li",{parentName:"ul"},"Pre-trained models for touch tasks are served on-demand based on initialized tasks"),(0,o.kt)("li",{parentName:"ul"},"Extendable framework for introducing new tasks"),(0,o.kt)("li",{parentName:"ul"},"Reusable framework for reducing boilerplate code across touch experiments and applications")),(0,o.kt)("h2",{id:"in-beta"},"In Beta"),(0,o.kt)("p",null,"PyTouch is currently in beta. Backwards compatability may break with minor version changes until release ",(0,o.kt)("inlineCode",{parentName:"p"},"1.0.0")),(0,o.kt)("h2",{id:"versions"},"Versions"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"PyTouch Release"),(0,o.kt)("th",{parentName:"tr",align:null},"Notes"),(0,o.kt)("th",{parentName:"tr",align:null},"Python Versions"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"0.4.0")),(0,o.kt)("td",{parentName:"tr",align:null},"Initial Release"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"3.7 - 3.9"))))))}u.isMDXComponent=!0}}]);